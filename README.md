# humanoid

## Problematic

One of the biggest challenges in web scraping is blocking which can be caused by hundreds of different reasons. However, we can reduce all of
these reasons to a single fact :
> web scrapers appears differently to websites and servers compared to a web browser used by a normal internet user.

## Objective

The purpose of this repository is to list all factors that can be used by security systems to differentiate between normal users and web scrapers, and to suggest possible implementations to imitate a normal users behavior.
